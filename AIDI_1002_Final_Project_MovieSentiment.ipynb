{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f459daa",
      "metadata": {
        "id": "9f459daa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from unidecode import unidecode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "with open('example.txt', 'w') as f:\n",
        "  f.write('some content')\n",
        "\n",
        "files.download('example.txt')"
      ],
      "metadata": {
        "id": "XlWrHW-VMJQj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ccea166e-e6d2-4645-c7e9-08401a0bcfd5"
      },
      "id": "XlWrHW-VMJQj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_aa205849-bd50-44fd-af3a-d5211b583bdd\", \"example.txt\", 12)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e325ee52",
      "metadata": {
        "id": "e325ee52",
        "outputId": "a291d3b1-fccf-4c40-d80d-2d1b85e83f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-37471a3a-fb43-4182-a4fc-5871d072b4e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37471a3a-fb43-4182-a4fc-5871d072b4e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-37471a3a-fb43-4182-a4fc-5871d072b4e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-37471a3a-fb43-4182-a4fc-5871d072b4e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "df_movie = pd.read_csv('IMDB-Dataset.csv')\n",
        "df_movie.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a65aab1",
      "metadata": {
        "id": "6a65aab1",
        "outputId": "f91bf1fb-6fde-42f0-d3b2-d54d01e726d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  One of the other reviewers has mentioned that ...          1\n",
              "1  A wonderful little production. <br /><br />The...          1\n",
              "2  I thought this was a wonderful way to spend ti...          1\n",
              "3  Basically there's a family where a little boy ...          0\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e2ac84a-3857-4fa4-8f27-e3c33b3bda50\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e2ac84a-3857-4fa4-8f27-e3c33b3bda50')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e2ac84a-3857-4fa4-8f27-e3c33b3bda50 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e2ac84a-3857-4fa4-8f27-e3c33b3bda50');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "df_movie['sentiment'] = df_movie['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "df_movie.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd43c768",
      "metadata": {
        "id": "bd43c768",
        "outputId": "4290eacd-5ecb-4041-8d4a-9cbf0d9c32ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review  sentiment\n",
            "0      One of the other reviewers has mentioned that ...          1\n",
            "1      A wonderful little production. <br /><br />The...          1\n",
            "2      I thought this was a wonderful way to spend ti...          1\n",
            "3      Basically there's a family where a little boy ...          0\n",
            "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
            "...                                                  ...        ...\n",
            "49995  I thought this movie did a down right good job...          1\n",
            "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
            "49997  I am a Catholic taught in parochial elementary...          0\n",
            "49998  I'm going to have to disagree with the previou...          0\n",
            "49999  No one expects the Star Trek movies to be high...          0\n",
            "\n",
            "[50000 rows x 2 columns]\n",
            "                                              review  sentiment\n",
            "0  one of the other reviewers has mentioned that ...          1\n",
            "1  a wonderful little production the filming tech...          1\n",
            "2  i thought this was a wonderful way to spend ti...          1\n",
            "3  basically there s a family where a little boy ...          0\n",
            "4  petter mattei s love in the time of money is a...          1\n",
            "5  probably my all time favorite movie a story of...          1\n",
            "6  i sure would like to see a resurrection of a u...          1\n",
            "7  this show was an amazing fresh innovative idea...          0\n",
            "8  encouraged by the positive comments about this...          0\n",
            "9  if you like original gut wrenching laughter yo...          1\n"
          ]
        }
      ],
      "source": [
        "#Data cleaning\n",
        "\n",
        "import re\n",
        "import html\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def lower(review):\n",
        "    return review.lower()\n",
        "\n",
        "def deletePunctuation(x):\n",
        "    return re.sub(r'[^\\w\\s]', ' ', x)\n",
        "\n",
        "def deleteSpaces(x):\n",
        "    return re.sub(r'\\s+', ' ', x)\n",
        "\n",
        "def unescape(x):\n",
        "    return html.unescape(x)\n",
        "\n",
        "def deleteHtmlTags(x):\n",
        "    return BeautifulSoup(x, \"lxml\").text\n",
        "\n",
        "def cleanData1(X):\n",
        "    X.review = X.review.apply(lower)\n",
        "    X.review = X.review.apply(deleteHtmlTags)\n",
        "    X.review = X.review.apply(unidecode)\n",
        "    X.review = X.review.apply(deletePunctuation)\n",
        "    X.review = X.review.apply(unescape)\n",
        "    X.review = X.review.apply(deleteSpaces)\n",
        "\n",
        "print(df_movie)\n",
        "cleanData1(df_movie)\n",
        "\n",
        "print(df_movie[:10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2bee399",
      "metadata": {
        "id": "e2bee399",
        "outputId": "45185981-20ce-488b-8167-24a3c8518b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-7f0e1425a2e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mstop_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"english\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlemmatizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'*'\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n%s\\n%s\\n%s\\n'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/lib/nltk_data'\n**********************************************************************\n"
          ]
        }
      ],
      "source": [
        "#Data Cleaning 2\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
        "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
        "    text = [word for word in text if not word in stop_words]\n",
        "    text = \" \".join(text)\n",
        "    return text\n",
        "\n",
        "df_movie['Processed_Reviews'] =df_movie.review.apply(lambda x: clean_text(x))\n",
        "df_movie.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52787c2a",
      "metadata": {
        "id": "52787c2a",
        "outputId": "15b9d6b8-8f7a-402e-e162-d89bc929b6cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "123.17134"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_movie.Processed_Reviews.apply(lambda x: len(x.split(\" \"))).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9a1a2ba8",
      "metadata": {
        "id": "9a1a2ba8",
        "outputId": "ea65be9e-30dc-43d8-ca34-e5b2e62b186a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "400/400 [==============================] - 38s 90ms/step - loss: 0.3629 - accuracy: 0.8366 - val_loss: 0.2724 - val_accuracy: 0.8854\n",
            "Epoch 2/3\n",
            "400/400 [==============================] - 33s 84ms/step - loss: 0.2305 - accuracy: 0.9092 - val_loss: 0.2845 - val_accuracy: 0.8784\n",
            "Epoch 3/3\n",
            "400/400 [==============================] - 33s 82ms/step - loss: 0.1849 - accuracy: 0.9293 - val_loss: 0.3060 - val_accuracy: 0.8853\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: sentiment-score-model\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: sentiment-score-model\\assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000015A08DC5070> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000015A08DC5A90> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "#Train And Save Model\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Convolution1D\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "max_features = 6000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(df_movie['Processed_Reviews'])\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(df_movie['Processed_Reviews'])\n",
        "\n",
        "maxlen = 130\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "y = df_movie['sentiment']\n",
        "\n",
        "embed_size = 128\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_size))\n",
        "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(20, activation=\"relu\"))\n",
        "model.add(Dropout(0.05))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 100\n",
        "epochs = 3\n",
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
        "model.save('sentiment-score-model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0965372",
      "metadata": {
        "id": "e0965372",
        "outputId": "c9714d42-f448-4df1-d8d4-6988fdba6fd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your movie name: Spider Man No Way Home\n",
            "Looking For Tweets:  #SpiderManNoWayHome\n"
          ]
        }
      ],
      "source": [
        "movie = input(\"Enter your movie name: \")\n",
        "movie_hashtag='#'+movie.replace('/n','').replace(' ','')\n",
        "print(\"Looking For Tweets: \", movie_hashtag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8df3f243",
      "metadata": {
        "id": "8df3f243",
        "outputId": "cadccc4d-5da5-49b6-f763-b9215d532467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response(data=[<Tweet id=1515075755033604105 text='@ScottFeinberg We dropped 2 pods on #SpiderManNoWayHome \\n\\nInitial review:\\n\\nApple https://t.co/sr0sfdXCPt\\nSpotify https://t.co/uETgzVVYdr\\n\\nFollow up discussing the Multiverse:\\n\\nApple https://t.co/bATGfAhRgu\\nSpotify https://t.co/tTcucCiIze'>, <Tweet id=1515024930286764032 text=\"My ★★★★½ review of Spider-Man: No Way Home on Letterboxd\\n\\nAbsolutely Tom Holland's best run as #SpiderMan\\n\\n https://t.co/6OBiJQvA3b\\n\\n#SpiderManNoWayHome\">, <Tweet id=1514617111192096768 text='The Dan Richardson Show Episode 175: Spider-Man: No Way Home Spoiler Review\\nhttps://t.co/VjTPPUX11C\\n\\nIn which, I finally do a spoiler review for #SpiderManNoWayHome In honor of the Blu Ray release!!!!'>, <Tweet id=1514585181235163136 text='My review of the superhero sequel… #SpiderManNoWayHome #TomHolland https://t.co/nR2I98KCqz'>, <Tweet id=1514573477201727489 text='Spider-Man: No Way Home has arrived on the 4K UHD format and Cereal At Midnight has your in-depth review! How does the disc look, what special features are included, and is this movie worth adding to your collection? #SpiderManNoWayHome #SpiderMan \\nhttps://t.co/RHvqkkey29'>, <Tweet id=1514496261440815106 text='New #HotToys unboxing &amp; review on my Youtube channel - Spider-Man Black &amp; Gold Suit\\n\\n#SpiderManNoWayHome  #ホットトイズ\\n\\nhttps://t.co/ARXIMcnZYC'>, <Tweet id=1514319704743153670 text='Is MORBIUS the WORST superhero movie EVER?!? -- HARD Review https://t.co/iSqlAcQu96 via @YouTube #MorbiusSweep #morbius  #sony #SpiderManNoWayHome #JaredLeto'>, <Tweet id=1514206123338911752 text='Hot Toys Review | Spider-Man Black &amp; Gold Suit (Spider-Man No Way Home) \\n\\n“The #HotToys Black &amp; Gold Spidey from #SpiderManNoWayHome isn’t a perfect figure but is still worth adding to your collection” read @ThomasStorai’s review:⬇️ https://t.co/d38ROTjpsK'>, <Tweet id=1514103869550301185 text='Is it safe to do a review of Spider-Man No Way Home on YouTube or is it gonna be dicey cuz of spoiler content and copyright claims? @YouTube \\n\\n#YouTube #SpiderMan #SpiderManNoWayHome'>, <Tweet id=1514006135195398146 text='#SpiderManNoWayHome is now available on 4K, Blu-Ray, DVD, and Digital with over 80 minutes of bonus content! \\n\\nBut is the extra #SpiderMan content worth it? Find out in our review of the Spider-Man: No Way Home home media release\\n\\nhttps://t.co/VfsFYdqqnQ'>], includes={}, errors=[], meta={'newest_id': '1515075755033604105', 'oldest_id': '1514006135195398146', 'result_count': 10, 'next_token': 'b26v89c19zqg8o3fpytmp4pk2g0ejbpby99u5spqcagl9'})\n"
          ]
        }
      ],
      "source": [
        "#Getting Twitter Feed:\n",
        "import tweepy\n",
        "import config\n",
        "\n",
        "client=tweepy.Client(bearer_token=config.BEARER_TOKEN)\n",
        "query='review '+movie_hashtag+' -is:retweet lang:en -has:media'\n",
        "response=client.search_recent_tweets(query=query, max_results=10)\n",
        "#print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "132bffc2",
      "metadata": {
        "id": "132bffc2"
      },
      "outputs": [],
      "source": [
        "lst_movie_reviews_from_twtr=[]\n",
        "for tweet in response.data:\n",
        "    lst_movie_reviews_from_twtr.append(tweet.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "215d7c62",
      "metadata": {
        "id": "215d7c62",
        "outputId": "abc78b24-2659-41cd-a8f6-f5a23220bc52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(lst_movie_reviews_from_twtr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a61d3240",
      "metadata": {
        "id": "a61d3240",
        "outputId": "304e5257-3c9f-4b14-998d-49a0d12765e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "prediction: [[0.19055247]\n",
            " [0.28203535]\n",
            " [0.67855877]\n",
            " [0.53518677]\n",
            " [0.8954531 ]\n",
            " [0.13322309]\n",
            " [0.04018784]\n",
            " [0.8442749 ]\n",
            " [0.02998617]\n",
            " [0.822474  ]]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "reconstructed_model = keras.models.load_model(\"sentiment-score-model\")\n",
        "\n",
        "\n",
        "#ex_text_str = \"Another cash cow from Marvel. Never mind with a quality script. Let's just pump this crap out as fast as possible to cash in on the fame of Marvel. It's sick to know that Stan Lee sold out. This movie deserves negative stars. It sucks that bad.\"\n",
        "\n",
        "data_test = {'review':lst_movie_reviews_from_twtr}\n",
        "df_test = pd.DataFrame(data=data_test)\n",
        "df_test.head()\n",
        "df_test[\"review\"]=df_test.review.apply(lambda x: clean_text(x))\n",
        "\n",
        "list_sentences_test = df_test[\"review\"]\n",
        "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
        "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
        "prediction = reconstructed_model.predict(X_te)\n",
        "print(\"prediction:\",prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db43e68b",
      "metadata": {
        "id": "db43e68b",
        "outputId": "fb74d51c-6123-4f64-e630-ab03a8440984"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>Sentiment Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@ScottFeinberg We drop 2 pod #SpiderManNoWayHo...</td>\n",
              "      <td>0.190552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>My ★★★★½ review Spider-Man: No Way Home Letter...</td>\n",
              "      <td>0.282035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The Dan Richardson Show Episode 175: Spider-Ma...</td>\n",
              "      <td>0.678559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My review superhero sequel… #SpiderManNoWayHom...</td>\n",
              "      <td>0.535187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Spider-Man: No Way Home ha arrive 4K UHD forma...</td>\n",
              "      <td>0.895453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>New #HotToys unbox &amp;amp; review Youtube channe...</td>\n",
              "      <td>0.133223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Is MORBIUS WORST superhero movie EVER?!? -- HA...</td>\n",
              "      <td>0.040188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Hot Toys Review | Spider-Man Black &amp;amp; Gold ...</td>\n",
              "      <td>0.844275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Is safe review Spider-Man No Way Home YouTube ...</td>\n",
              "      <td>0.029986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>#SpiderManNoWayHome available 4K, Blu-Ray, DVD...</td>\n",
              "      <td>0.822474</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  Sentiment Score\n",
              "0  @ScottFeinberg We drop 2 pod #SpiderManNoWayHo...         0.190552\n",
              "1  My ★★★★½ review Spider-Man: No Way Home Letter...         0.282035\n",
              "2  The Dan Richardson Show Episode 175: Spider-Ma...         0.678559\n",
              "3  My review superhero sequel… #SpiderManNoWayHom...         0.535187\n",
              "4  Spider-Man: No Way Home ha arrive 4K UHD forma...         0.895453\n",
              "5  New #HotToys unbox &amp; review Youtube channe...         0.133223\n",
              "6  Is MORBIUS WORST superhero movie EVER?!? -- HA...         0.040188\n",
              "7  Hot Toys Review | Spider-Man Black &amp; Gold ...         0.844275\n",
              "8  Is safe review Spider-Man No Way Home YouTube ...         0.029986\n",
              "9  #SpiderManNoWayHome available 4K, Blu-Ray, DVD...         0.822474"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['Sentiment Score']=prediction\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "538cb92e",
      "metadata": {
        "id": "538cb92e",
        "outputId": "6f022e81-8aa7-479f-9574-a2256dd020ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maybe Watch Average Review Score: 44.519323110580444 %\n"
          ]
        }
      ],
      "source": [
        "p_mean=prediction.mean()\n",
        "if p_mean>=0.6:\n",
        "    print('Must Watch','Average Review Score:',p_mean*100,'%')\n",
        "if p_mean>0.4 and p_mean<0.6:\n",
        "    print('Maybe Watch','Average Review Score:',p_mean*100,'%')\n",
        "if p_mean<=0.4:\n",
        "    print('Not Worth It','Average Review Score:',p_mean*100,'%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13236026",
      "metadata": {
        "id": "13236026"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "AIDI_1002_Final_Project_MovieSentiment.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}